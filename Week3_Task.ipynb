{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as func\n",
    "from PIL import Image\n",
    "from datasetCreator import ImageSubset\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "from models import VGG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv('data/BNPP_DT_test_with_ages.csv')\n",
    "val = pd.read_csv('data/BNPP_DT_val_with_ages.csv')\n",
    "train = pd.read_csv('data/BNPP_DT_train_with_ages.csv')\n",
    "f = h5py.File('data/bnpp_frontalonly_1024_10.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "unique_key           Nisrana_50554206_img1\n",
       "bnpp_value_log                    0.690196\n",
       "BNPP_weight                              1\n",
       "PNA_mask                              None\n",
       "PNA_wight_mask                           1\n",
       "BNP_value                              4.9\n",
       "age_at_sampletime                       49\n",
       "Name: 6, dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.iloc[6,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#list(f.keys())\n",
    "data = {}\n",
    "ind=0\n",
    "for key in list(f.keys()):\n",
    "    image = f[key][:]\n",
    "    #resizing to 224 x 224\n",
    "    formatted = (image * 255 / np.max(image)).astype('uint8')\n",
    "    img = Image.fromarray(formatted).resize((224,224))\n",
    "    data[ind]=[key,img]\n",
    "    #img_tensor = transform(img)\n",
    "    #data[key] = img_tensor\n",
    "    img.save(f'data/images/{key}.jpg')\n",
    "    ind+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<datasetCreator.ImageSubset at 0x23cc121fbe0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.PILToTensor(),\n",
    "    transforms.Normalize(mean=(0.5), std=(0.5))\n",
    "])\n",
    "train_data = ImageSubset(csv_file = 'data/BNPP_DT_train_with_ages.csv', data=data, img_dir='data/images/')\n",
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unique_key</th>\n",
       "      <th>bnpp_value_log</th>\n",
       "      <th>BNPP_weight</th>\n",
       "      <th>PNA_mask</th>\n",
       "      <th>PNA_wight_mask</th>\n",
       "      <th>BNP_value</th>\n",
       "      <th>age_at_sampletime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [unique_key, bnpp_value_log, BNPP_weight, PNA_mask, PNA_wight_mask, BNP_value, age_at_sampletime]\n",
       "Index: []"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[train['unique_key']=='Umellum_52452344_img1']\n",
    "#train_data.__getitem__(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(train_data,batch_size=16)\n",
    "train_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "model = VGG('VGG16').to(device)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn(2, 1, 224, 224)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = model(x)\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"[INFO]: Computation device: {device}\")\n",
    "epochs = 10\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "print(f\"[INFO]: {total_params:,} total parameters.\")\n",
    "total_trainable_params = sum(\n",
    "    p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f\"[INFO]: {total_trainable_params:,} trainable parameters.\")\n",
    "# the loss function\n",
    "criterion = nn.L1Loss()\n",
    "# the optimizer\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001, weight_decay=0.0005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training\n",
    "def train(model, trainloader, optimizer, criterion):\n",
    "    model.train()\n",
    "    print('Training')\n",
    "    train_running_loss = 0.0\n",
    "    train_running_correct = 0\n",
    "    counter = 0\n",
    "    for i, data in tqdm(enumerate(trainloader), total=len(trainloader)):\n",
    "        counter += 1\n",
    "\n",
    "        image, bnpp = data[0], data[2]\n",
    "        #print(i)\n",
    "        #print(data)\n",
    "        #print(data[0])\n",
    "        #print(data[1])\n",
    "        #print(data[2])\n",
    "        #break\n",
    "        image = image.to(device)\n",
    "        bnpp = bnpp.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        # forward pass\n",
    "        outputs = model(image.float())\n",
    "        # calculate the loss\n",
    "        loss = criterion(outputs, bnpp)\n",
    "        train_running_loss += loss.item()\n",
    "        # calculate the accuracy\n",
    "        #_, preds = torch.max(outputs.data, 1)\n",
    "        #train_running_correct += (preds == labels).sum().item()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    epoch_loss = train_running_loss / counter\n",
    "    #epoch_acc = 100. * (train_running_correct / len(trainloader.dataset))\n",
    "    return epoch_loss, epoch_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train(model, train_dataloader,optimizer,criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# our transforms will differ a bit from the VGG paper\n",
    "# as we are using the MNIST dataset, so, we will directly resize...\n",
    "# ... the images to 224x224 and not crop them and we will not use...\n",
    "# ... any random flippings also\n",
    "train_transform = transforms.Compose(\n",
    "    [transforms.Resize((224, 224)),\n",
    "     transforms.ToTensor(),\n",
    "     transforms.Normalize(mean=(0.5), std=(0.5))])\n",
    "valid_transform = transforms.Compose(\n",
    "    [transforms.Resize((224, 224)),\n",
    "     transforms.ToTensor(),\n",
    "     transforms.Normalize(mean=(0.5), std=(0.5))])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "b629c3126b5df0b3c19ac5f524890cb3a3a2e86c1a2f2c4b1c29287aa73e65d0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
